{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model on IRIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data set\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The sample program in this document builds and tests a model that classifies Iris flowers into three different species \n",
    "based on the size of their sepals and petals.\n",
    "\n",
    "You will train a model using the Iris data set. The Iris data set contains four features and one label. \n",
    "The four features identify the following botanical characteristics of individual Iris flowers:\n",
    "\n",
    "sepal length\n",
    "sepal width\n",
    "petal length\n",
    "petal width\n",
    "Based on this information, you can define a few helpful constants for parsing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us define contants which will help later\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
      "2194/2194 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
      "573/573 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "#Here we use Keras (a module inside of tensorflow) to grab our dataset and read them into pandas dataframe\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets have look at our data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we can pop the species column off and use that as our label\n",
    "train_y =train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "train.head() #the species column is now gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape #we have 120 entries with 4 features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create input functions\n",
    "You must create input functions to supply data for training, evaluating, and prediction.\n",
    "\n",
    "An input function is a function that returns a tf.data.Dataset object which outputs the following two-element tuple:\n",
    "\n",
    "features - A Python dictionary in which:\n",
    "Each key is the name of a feature.\n",
    "Each value is an array containing all of that feature's values.\n",
    "label - An array containing the values of the label for every example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    \"\"\"An input function for training or evaluating\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the feature columns\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A feature column is an object describing how the model should use raw input data from the features dictionary. \n",
    "When you build an Estimator model, you pass it a list of feature columns that describes each of the features you \n",
    "want the model to use. The tf.feature_column module provides many options for representing data to the model.\n",
    "\n",
    "For Iris, the 4 raw features are numeric values, so you'll build a list of feature columns to tell the Estimator model \n",
    "to represent each of the four features as 32-bit floating-point values. Therefore, the code to create the feature column \n",
    "is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-8574ab75ad72>:4: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    }
   ],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate an estimator\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The Iris problem is a classic classification problem. Fortunately, \n",
    "TensorFlow provides several pre-made classifier Estimators, including:\n",
    "\n",
    "tf.estimator.DNNClassifier for deep models that perform multi-class classification.(Deep Neural Networks)\n",
    "tf.estimator.DNNLinearCombinedClassifier for wide & deep models.\n",
    "tf.estimator.LinearClassifier for classifiers based on linear models.\n",
    "For the Iris problem, tf.estimator.DNNClassifier seems like the best choice. Here's how you instantiated this Estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-a10959187169>:2: DNNClassifierV2.__init__ (from tensorflow_estimator.python.estimator.canned.dnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\head_utils.py:59: MultiClassHead.__init__ (from tensorflow_estimator.python.estimator.head.multi_class_head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py:759: Estimator.__init__ (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1844: RunConfig.__init__ (from tensorflow_estimator.python.estimator.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\neela\\AppData\\Local\\Temp\\tmpzbsh7ctu\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\neela\\\\AppData\\\\Local\\\\Temp\\\\tmpzbsh7ctu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "Train the model by calling the Estimator's train method as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:385: StopAtStepHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\legacy\\adagrad.py:93: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\model_fn.py:250: EstimatorSpec.__new__ (from tensorflow_estimator.python.estimator.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1416: NanTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1419: LoggingTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py:232: SecondOrStepTimer.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1456: CheckpointSaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:579: StepCounterHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:586: SummarySaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\neela\\AppData\\Local\\Temp\\tmpzbsh7ctu\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1455: SessionRunArgs.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1454: SessionRunContext.__init__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1474: SessionRunValues.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:loss = 1.4970417, step = 0\n",
      "INFO:tensorflow:global_step/sec: 350.429\n",
      "INFO:tensorflow:loss = 0.8877608, step = 100 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.366\n",
      "INFO:tensorflow:loss = 0.80035686, step = 200 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.855\n",
      "INFO:tensorflow:loss = 0.7246342, step = 300 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.065\n",
      "INFO:tensorflow:loss = 0.6893569, step = 400 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.782\n",
      "INFO:tensorflow:loss = 0.66167283, step = 500 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.231\n",
      "INFO:tensorflow:loss = 0.6243857, step = 600 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.514\n",
      "INFO:tensorflow:loss = 0.59407234, step = 700 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.18\n",
      "INFO:tensorflow:loss = 0.58464444, step = 800 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.108\n",
      "INFO:tensorflow:loss = 0.5674938, step = 900 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.335\n",
      "INFO:tensorflow:loss = 0.5379701, step = 1000 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.733\n",
      "INFO:tensorflow:loss = 0.54156893, step = 1100 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 558.891\n",
      "INFO:tensorflow:loss = 0.52717245, step = 1200 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.224\n",
      "INFO:tensorflow:loss = 0.5079725, step = 1300 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.741\n",
      "INFO:tensorflow:loss = 0.49701995, step = 1400 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.102\n",
      "INFO:tensorflow:loss = 0.48598802, step = 1500 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.208\n",
      "INFO:tensorflow:loss = 0.47160324, step = 1600 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.435\n",
      "INFO:tensorflow:loss = 0.46906358, step = 1700 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.264\n",
      "INFO:tensorflow:loss = 0.4577747, step = 1800 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.133\n",
      "INFO:tensorflow:loss = 0.45547372, step = 1900 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.431\n",
      "INFO:tensorflow:loss = 0.45005602, step = 2000 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.455\n",
      "INFO:tensorflow:loss = 0.4446054, step = 2100 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.456\n",
      "INFO:tensorflow:loss = 0.4341623, step = 2200 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.521\n",
      "INFO:tensorflow:loss = 0.42166162, step = 2300 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.46\n",
      "INFO:tensorflow:loss = 0.41705745, step = 2400 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.988\n",
      "INFO:tensorflow:loss = 0.41955563, step = 2500 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.455\n",
      "INFO:tensorflow:loss = 0.41484368, step = 2600 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.899\n",
      "INFO:tensorflow:loss = 0.4106907, step = 2700 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.335\n",
      "INFO:tensorflow:loss = 0.4000471, step = 2800 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.841\n",
      "INFO:tensorflow:loss = 0.3944633, step = 2900 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.169\n",
      "INFO:tensorflow:loss = 0.39203826, step = 3000 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 435.087\n",
      "INFO:tensorflow:loss = 0.39102793, step = 3100 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.68\n",
      "INFO:tensorflow:loss = 0.3737844, step = 3200 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.415\n",
      "INFO:tensorflow:loss = 0.38370705, step = 3300 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.075\n",
      "INFO:tensorflow:loss = 0.3594153, step = 3400 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.87\n",
      "INFO:tensorflow:loss = 0.3728105, step = 3500 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.946\n",
      "INFO:tensorflow:loss = 0.36231923, step = 3600 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.542\n",
      "INFO:tensorflow:loss = 0.35652512, step = 3700 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.736\n",
      "INFO:tensorflow:loss = 0.36256927, step = 3800 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.037\n",
      "INFO:tensorflow:loss = 0.34991145, step = 3900 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.405\n",
      "INFO:tensorflow:loss = 0.3479639, step = 4000 (0.231 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 447.152\n",
      "INFO:tensorflow:loss = 0.34023803, step = 4100 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.877\n",
      "INFO:tensorflow:loss = 0.34288985, step = 4200 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.456\n",
      "INFO:tensorflow:loss = 0.3455437, step = 4300 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.888\n",
      "INFO:tensorflow:loss = 0.32012576, step = 4400 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 432.24\n",
      "INFO:tensorflow:loss = 0.32950774, step = 4500 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.207\n",
      "INFO:tensorflow:loss = 0.32899565, step = 4600 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.302\n",
      "INFO:tensorflow:loss = 0.32014537, step = 4700 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.816\n",
      "INFO:tensorflow:loss = 0.3223017, step = 4800 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.504\n",
      "INFO:tensorflow:loss = 0.3107481, step = 4900 (0.234 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\neela\\AppData\\Local\\Temp\\tmpzbsh7ctu\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.3196904.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x2761d46d4f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    steps=5000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note that you wrap up your input_fn call in a lambda to capture the arguments while providing an input \n",
    "function that takes no arguments, as expected by the Estimator. \n",
    "The steps argument tells the method to stop training after a number of training steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the trained model\n",
    "Now that the model has been trained, you can get some statistics on its performance. \n",
    "The following code block evaluates the accuracy of the trained model on the test data:\n",
    "\n",
    "Unlike the call to the train method, you did not pass the steps argument to evaluate. The input_fn for eval only yields a single epoch of data.\n",
    "\n",
    "The eval_result dictionary also contains the average_loss (mean loss per sample), the loss (mean loss per mini-batch) and the value of the estimator's global_step (the number of training iterations it underwent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-10-04T23:23:48\n",
      "WARNING:tensorflow:From C:\\Users\\neela\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\evaluation.py:260: FinalOpsHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\neela\\AppData\\Local\\Temp\\tmpzbsh7ctu\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.39561s\n",
      "INFO:tensorflow:Finished evaluation at 2023-10-04-23:23:48\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.93333334, average_loss = 0.3739758, global_step = 5000, loss = 0.3739758\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\neela\\AppData\\Local\\Temp\\tmpzbsh7ctu\\model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions (inferring) from the trained model\n",
    "You now have a trained model that produces good evaluation results.\n",
    "You can now use the trained model to predict the species of an Iris flower based on some unlabeled measurements.\n",
    "As with training and evaluation, you make predictions using a single function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric value as prompted.\n",
      "SepalLength: 8.9\n",
      "SepalWidth: 6.3\n",
      "PetalLength: 2.6\n",
      "PetalWidth: 7.2\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\neela\\AppData\\Local\\Temp\\tmpzbsh7ctu\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (87.2%), expected \"Setosa\"\n",
      "Prediction is \"Versicolor\" (54.8%), expected \"Versicolor\"\n",
      "Prediction is \"Virginica\" (66.7%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions from the model\n",
    "#expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "#predict_x = {\n",
    " #   'SepalLength': [5.1, 5.9, 6.9],\n",
    "  #  'SepalWidth': [3.3, 3.0, 3.1],\n",
    "   # 'PetalLength': [1.7, 4.2, 5.4],\n",
    "    #'PetalWidth': [0.5, 1.5, 2.1],\n",
    "#}\n",
    "\n",
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = [\n",
    "    'SepalLength',\n",
    "    'SepalWidth',\n",
    "    'PetalLength',\n",
    "    'PetalWidth']\n",
    "\n",
    "predict={}\n",
    "\n",
    "print(\"Please type numeric value as prompted.\")\n",
    "for feature in features:\n",
    "    valid =True\n",
    "    while valid :\n",
    "        val= input(feature + \": \")\n",
    "        if not val.isdigit(): valid=False\n",
    "\n",
    "            \n",
    "predict[feature] = [float(val)] \n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict_x))\n",
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\n",
    "        SPECIES[class_id], 100 * probability, expec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
